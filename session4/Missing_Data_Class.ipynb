{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MissingValues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If we create a list of numbers, integers or floats, and put in the None type,\n",
    "# pandas automatically converts this to a special floating point value designated as NaN, \n",
    "# which stands for \"Not a Number\".\n",
    "\n",
    "# So lets create a list with a None value in it\n",
    "numbers = [1, 2, None]\n",
    "# And turn that into a series\n",
    "pd.Series(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NaN is *NOT* equivilent to None and when we try the equality test, the result is False.\n",
    "\n",
    "# Lets bring in numpy which allows us to generate an NaN value\n",
    "import numpy as np\n",
    "# And lets compare it to None\n",
    "np.nan == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# It turns out that you actually can't do an equality test of NAN to itself. When you do, \n",
    "# the answer is always False. \n",
    "\n",
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instead, you need to use special functions to test for the presence of not a number, \n",
    "# such as the Numpy library isnan().\n",
    "\n",
    "np.isnan(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So keep in mind when you see NaN, it's meaning is similar to None, but it's a \n",
    "# numeric value and treated differently for efficiency reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's load a piece of data\n",
    "#df = pd.read_csv('class_grades.csv')\n",
    "df= pd.read_csv('https://raw.githubusercontent.com/calovids/IMPRS-Python-Workshop/main/data/class_grades.csv')\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can actually use the function .isnull() to create a boolean mask of the whole dataframe. This effectively\n",
    "# broadcasts the isnull() function to every cell of data.\n",
    "mask=df.isnull()\n",
    "mask.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NA_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pandas is pretty good at detecting missing values directly from underlying data formats, like CSV files.\n",
    "# Although most missing valuse are often formatted as NaN, NULL, None, or N/A, sometimes missing values are\n",
    "# not labeled so clearly. For example, Some social scientists regularly use the value of 99\n",
    "# in binary categories to indicate a missing value. The pandas read_csv() function has a parameter called\n",
    "# na_values to let us specify the form of missing values. It allows scalar, string, list, or dictionaries to\n",
    "# be used.\n",
    "# \n",
    "# If you notice, at index 11, we have a strange value for the TakeHome variable.\n",
    "\n",
    "df.iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#If we open the csv file, we can we have a space there\n",
    "print(type(df.loc[11,'TakeHome']))\n",
    "\n",
    "#It can be very useful to redefine what shold be read as an NA\n",
    "#before loading the csv file:\n",
    "\n",
    "#df = pd.read_csv('class_grades.csv', na_values=['NA', ' ', 'NULL'])\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/calovids/IMPRS-Python-Workshop/main/data/class_grades.csv', na_values=['NA', ' ', 'NULL'])\n",
    "df.iloc[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This can be useful for processing rows based on certain columns of data. Another useful operation is to be\n",
    "# able to drop all of those rows which have any missing data, which can be done with the dropna() function.\n",
    "df.dropna().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note how the rows indexed with 2, 3, 7, and 11 are now gone. One of the handy functions that Pandas has for\n",
    "# working with missing values is the filling function, fillna(). This function takes a number or parameters.\n",
    "# You could pass in a single value which is called a scalar value to change all of the missing data to one\n",
    "# value. This isn't really applicable in this case, but it's a pretty common use case.\n",
    "\n",
    "# So, if we wanted to fill all missing values with 0, we would use fillna\n",
    "df.fillna(0, inplace=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that the inplace attribute causes pandas to fill the values inline and does not return a copy of the\n",
    "# dataframe, but instead modifies the dataframe you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Creating a sample DataFrame with missing values\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, np.nan, 3, 4, np.nan],\n",
    "    'B': [np.nan, 2, 3, np.nan, 5],\n",
    "    'C': [1, 2, np.nan, 4, 5]\n",
    "})\n",
    "\n",
    "# Filling missing values with a specific value\n",
    "df_fill_value = df.fillna(0)\n",
    "\n",
    "# Forward fill (propagate last valid observation forward)\n",
    "df_forward_fill = df.fillna(method='ffill')\n",
    "\n",
    "# Backward fill (propagate next valid observation backward)\n",
    "df_backward_fill = df.fillna(method='bfill')\n",
    "\n",
    "# Display the original and filled DataFrames\n",
    "print(\"Original DataFrame:\\n\", df)\n",
    "print(\"\\nDataFrame with fill value 0:\\n\", df_fill_value)\n",
    "print(\"\\nDataFrame with forward fill:\\n\", df_forward_fill)\n",
    "print(\"\\nDataFrame with backward fill:\\n\", df_backward_fill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also do customized fill-in to replace values with the replace() function. It allows replacement from\n",
    "# several approaches: value-to-value, list, dictionary, regex Let's generate a simple example\n",
    "df = pd.DataFrame({'A': [1, 1, 2, 3, 4],\n",
    "                   'B': [3, 6, 3, 8, 9],\n",
    "                   'C': ['a', 'b', 'c', 'd', 'e']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can replace 1's with 100, let's try the value-to-value approach\n",
    "df.replace(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about changing two values? Let's try the list approach For example, we want to change 1's to 100 and 3's\n",
    "# to 300\n",
    "df.replace([1, 3], [100, 300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex when replacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# What's really cool about pandas replacement is that it supports regex too!\n",
    "# Let's look at our data from the dataset logs\n",
    "#df = pd.read_csv(\"datasets/log.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/calovids/IMPRS-Python-Workshop/main/data/log.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To replace using a regex we make the first parameter to replace the regex pattern we want to match, the\n",
    "# second parameter the value we want to emit upon match, and then we pass in a third parameter \"regex=True\".\n",
    "\n",
    "# Imagine we want to detect all html pages in the \"video\" column, lets say that just means they end with\n",
    "# \".html\", and we want to overwrite that with the keyword \"webpage\". How could we accomplish this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's my solution, first matching any number of characters then ending in .html\n",
    "df.replace(to_replace=\".*.html$\", value=\"webpage\", regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last note on missing values. When you use statistical functions on DataFrames, these functions typically\n",
    "ignore missing values. For instance if you try and calculate the mean value of a DataFrame, the underlying\n",
    "NumPy function will ignore missing values. This is usually what you want but you should be aware that values\n",
    "are being excluded. Why you have missing values really matters depending upon the problem you are trying to\n",
    "solve. It might be unreasonable to infer missing values, for instance, if the data shouldn't exist in the\n",
    "first place."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
